# /api/query.py - ANA SORGULAMA MOTORU
from http.server import BaseHTTPRequestHandler
import json
import os
from datetime import datetime
from typing import Dict, List, Any

# Import modules
from excel_processor import excel_processor
from query_parser import query_parser
from filter_engine import filter_engine

class QueryEngine:
    """Ana sorgulama motoru"""
    
    def __init__(self):
        self.excel_data = None
        self.excel_url = "https://borsaanaliz-raporlar.vercel.app/raporlar/BORSAANALIZ_V11_TAM_06022026.xlsm"
    
    def load_excel_data(self) -> Dict:
        """Excel verilerini yÃ¼kle (cache'li)"""
        if self.excel_data is None:
            print("ğŸ“¥ Excel verileri yÃ¼kleniyor...")
            self.excel_data = excel_processor.read_excel_data(self.excel_url)
        return self.excel_data
    
    def execute_query(self, query: str, query_type: str = "natural") -> Dict:
        """Sorguyu Ã§alÄ±ÅŸtÄ±r"""
        start_time = datetime.now()
        
        try:
            # 1. Sorguyu parse et
            if query_type == "natural":
                parsed = query_parser.parse_natural_language(query)
            else:  # advanced
                try:
                    query_json = json.loads(query) if isinstance(query, str) else query
                    parsed = query_parser.parse_advanced_query(query_json)
                except:
                    parsed = query_parser.parse_natural_language(query)
            
            if not parsed.get("parsed_successfully"):
                return {
                    "success": False,
                    "error": "Sorgu anlaÅŸÄ±lamadÄ±",
                    "parsed_query": parsed
                }
            
            # 2. Excel verilerini yÃ¼kle
            excel_data = self.load_excel_data()
            all_hisseler = excel_data.get("hisseler", {})
            
            # 3. Filtrele ve sÄ±rala
            results = filter_engine.filter_and_sort(
                all_hisseler=all_hisseler,
                filters=parsed["filters"],
                sort_config=parsed["sorting"],
                limit=parsed["pagination"]["limit"]
            )
            
            # 4. Ä°statistikleri hesapla
            stats = self.calculate_stats(results, parsed["filters"])
            
            execution_time = (datetime.now() - start_time).total_seconds()
            
            return {
                "success": True,
                "query": query,
                "parsed_query": parsed,
                "results": results,
                "stats": stats,
                "execution_time": execution_time,
                "excel_info": {
                    "total_hisses": len(all_hisseler),
                    "excel_url": self.excel_url,
                    "load_time": excel_data.get("load_time", 0)
                }
            }
            
        except Exception as e:
            print(f"âŒ Sorgu Ã§alÄ±ÅŸtÄ±rma hatasÄ±: {e}")
            import traceback
            traceback.print_exc()
            return {
                "success": False,
                "error": str(e),
                "execution_time": (datetime.now() - start_time).total_seconds()
            }
    
    def calculate_stats(self, results: List[Dict], filters: List[Dict]) -> Dict:
        """Ä°statistikleri hesapla"""
        if not results:
            return {}
        
        stats = {
            "count": len(results),
            "avg_pearson55": 0,
            "avg_close": 0,
            "strong_positive": 0,
            "neutral": 0,
            "strong_negative": 0,
        }
        
        total_pearson = 0
        total_close = 0
        
        for result in results:
            # Pearson ortalamasÄ±
            pearson = result.get("Pearson55", 0)
            if isinstance(pearson, (int, float)):
                total_pearson += float(pearson)
            
            # Close ortalamasÄ±
            close = result.get("Close", 0)
            if isinstance(close, (int, float)):
                total_close += float(close)
            
            # Durum sayÄ±larÄ±
            durum = str(result.get("DURUM", "")).upper()
            if "GÃœÃ‡LÃœ POZÄ°TÄ°F" in durum:
                stats["strong_positive"] += 1
            elif "NÃ–TR" in durum:
                stats["neutral"] += 1
            elif "GÃœÃ‡LÃœ NEGATÄ°F" in durum:
                stats["strong_negative"] += 1
        
        if stats["count"] > 0:
            stats["avg_pearson55"] = round(total_pearson / stats["count"], 3)
            stats["avg_close"] = round(total_close / stats["count"], 2)
        
        return stats
    
    def format_results(self, result: Dict) -> str:
        """SonuÃ§larÄ± formatla"""
        if not result.get("success"):
            error = result.get("error", "Bilinmeyen hata")
            return f"âŒ **Sorgu HatasÄ±:** {error}"
        
        results = result.get("results", [])
        stats = result.get("stats", {})
        parsed = result.get("parsed_query", {})
        
        if not results:
            return "ğŸ” **SonuÃ§ bulunamadÄ±.**\n\nFiltrelerinizi gÃ¶zden geÃ§irin veya daha geniÅŸ kriterler deneyin."
        
        response_lines = []
        
        # BaÅŸlÄ±k
        response_lines.append(f"ğŸ“Š **SORGULAMA SONUÃ‡LARI**")
        response_lines.append("=" * 50)
        
        # Ä°statistikler
        response_lines.append(f"â€¢ **Bulunan Hisse:** {stats.get('count', 0)}")
        response_lines.append(f"â€¢ **Ortalama Pearson55:** {stats.get('avg_pearson55', 0)}")
        response_lines.append(f"â€¢ **Ortalama Fiyat:** {stats.get('avg_close', 0)} TL")
        response_lines.append(f"â€¢ **GÃ¼Ã§lÃ¼ Pozitif:** {stats.get('strong_positive', 0)}")
        response_lines.append(f"â€¢ **NÃ¶tr:** {stats.get('neutral', 0)}")
        response_lines.append(f"â€¢ **GÃ¼Ã§lÃ¼ Negatif:** {stats.get('strong_negative', 0)}")
        response_lines.append(f"â€¢ **Ã‡alÄ±ÅŸma SÃ¼resi:** {result.get('execution_time', 0):.2f}s")
        response_lines.append("")
        
        # Hisse listesi (ilk 10)
        response_lines.append("ğŸ† **EN Ä°YÄ° 10 HÄ°SSE:**")
        response_lines.append("")
        
        for i, hisse in enumerate(results[:10], 1):
            hisse_adi = hisse.get("hisse", "N/A")
            close = hisse.get("Close", "N/A")
            pearson = hisse.get("Pearson55", "N/A")
            vma = hisse.get("VMA trend algo", "N/A")
            durum = hisse.get("DURUM", "N/A")
            
            # Durum emojisi
            durum_upper = str(durum).upper()
            if "GÃœÃ‡LÃœ POZÄ°TÄ°F" in durum_upper:
                emoji = "ğŸŸ¢"
            elif "POZÄ°TÄ°F" in durum_upper:
                emoji = "ğŸŸ¢"
            elif "GÃœÃ‡LÃœ NEGATÄ°F" in durum_upper:
                emoji = "ğŸ”´"
            elif "NEGATÄ°F" in durum_upper:
                emoji = "ğŸ”´"
            elif "NÃ–TR" in durum_upper:
                emoji = "ğŸŸ¡"
            else:
                emoji = "âšª"
            
            response_lines.append(f"{i}. **{hisse_adi}** {emoji}")
            response_lines.append(f"   â€¢ Fiyat: **{close} TL**")
            response_lines.append(f"   â€¢ Pearson55: **{pearson}**")
            response_lines.append(f"   â€¢ VMA: {vma}")
            response_lines.append(f"   â€¢ Durum: {durum}")
            
            # Bollinger alt bandÄ±na uzaklÄ±k
            if "BB_LOWER" in hisse:
                bb_lower = hisse.get("BB_LOWER", 0)
                if isinstance(close, (int, float)) and isinstance(bb_lower, (int, float)) and bb_lower > 0:
                    distance = ((close - bb_lower) / bb_lower) * 100
                    response_lines.append(f"   â€¢ BB Alt BandÄ±: %{distance:.1f} uzak")
            
            response_lines.append("")
        
        if len(results) > 10:
            response_lines.append(f"â© **... ve {len(results) - 10} hisse daha**")
            response_lines.append("")
        
        # Filtre bilgisi
        response_lines.append("ğŸ” **Uygulanan Filtreler:**")
        filters = parsed.get("filters", [])
        if filters:
            for f in filters:
                field = f.get("field", "")
                operator = f.get("operator", "")
                value = f.get("value", "")
                response_lines.append(f"â€¢ {field} {operator} {value}")
        else:
            response_lines.append("â€¢ TÃ¼m hisseler")
        
        # SÄ±ralama bilgisi
        sorting = parsed.get("sorting", {})
        if sorting:
            field = sorting.get("field", "")
            order = "azalan" if sorting.get("order") == "DESC" else "artan"
            response_lines.append(f"â€¢ SÄ±ralama: {field} ({order})")
        
        response_lines.append("")
        response_lines.append("ğŸ’¡ **Ã–rnek sorgular:**")
        response_lines.append("â€¢ `Pearson55 >= 0.85 ve VMA POZÄ°TÄ°F`")
        response_lines.append("â€¢ `Regression kanalÄ± pozitif olanlar`")
        response_lines.append("â€¢ `BB alt bandÄ±na en yakÄ±n 10 hisse`")
        
        return "\n".join(response_lines)

# Global engine instance
query_engine = QueryEngine()

class QueryHandler(BaseHTTPRequestHandler):
    """HTTP Handler for query engine"""
    
    def do_GET(self):
        """Sistem durumu"""
        self.send_response(200)
        self.send_header('Content-type', 'application/json; charset=utf-8')
        self.end_headers()
        
        response = {
            "status": "online",
            "service": "BorsaAnaliz Query Engine",
            "version": "1.0-alpha",
            "endpoints": {
                "POST /api/query": "DoÄŸal dil sorgulama",
                "POST /api/query/advanced": "Advanced JSON sorgulama"
            },
            "capabilities": [
                "Pearson55/144/233 filtreleme",
                "VMA trend analizi",
                "Regression kanalÄ± filtreleme",
                "Bollinger BandÄ± analizi",
                "EMA trend analizi",
                "DoÄŸal TÃ¼rkÃ§e sorgu"
            ]
        }
        
        self.wfile.write(json.dumps(response, ensure_ascii=False, indent=2).encode('utf-8'))
    
    def do_POST(self):
        """Sorgu iÅŸleme"""
        try:
            content_length = int(self.headers.get('Content-Length', 0))
            post_data = self.rfile.read(content_length)
            data = json.loads(post_data)
            
            query = data.get('query', '')
            query_type = data.get('type', 'natural')
            
            if not query:
                self.send_error(400, "Query is required")
                return
            
            print(f"\n{'='*60}")
            print(f"ğŸš€ YENÄ° SORGULA: {query[:100]}...")
            print('='*60)
            
            # Sorguyu Ã§alÄ±ÅŸtÄ±r
            result = query_engine.execute_query(query, query_type)
            
            # FormatlÄ± yanÄ±t oluÅŸtur
            formatted_response = query_engine.format_results(result)
            
            # JSON yanÄ±tÄ± hazÄ±rla
            response_data = {
                "success": result.get("success", False),
                "query": query,
                "response": formatted_response,
                "stats": result.get("stats", {}),
                "execution_time": result.get("execution_time", 0),
                "result_count": len(result.get("results", [])),
                "engine_version": "1.0-alpha",
                "timestamp": datetime.now().isoformat()
            }
            
            # Raw results iÃ§in (debug)
            if data.get("debug", False):
                response_data["raw_results"] = result.get("results", [])
                response_data["parsed_query"] = result.get("parsed_query", {})
            
            # YanÄ±tÄ± gÃ¶nder
            self.send_response(200)
            self.send_header('Content-type', 'application/json; charset=utf-8')
            self.end_headers()
            
            self.wfile.write(json.dumps(response_data, ensure_ascii=False, indent=2).encode('utf-8'))
            
            print(f"âœ… Sorgu tamamlandÄ±: {response_data['result_count']} sonuÃ§, {response_data['execution_time']:.2f}s")
            print('='*60 + '\n')
            
        except json.JSONDecodeError:
            self.send_error(400, "Invalid JSON")
        except Exception as e:
            print(f"âŒ Handler hatasÄ±: {e}")
            import traceback
            traceback.print_exc()
            
            self.send_response(500)
            self.send_header('Content-type', 'application/json; charset=utf-8')
            self.end_headers()
            
            error_response = {
                "success": False,
                "error": str(e),
                "query": query if 'query' in locals() else ""
            }
            
            self.wfile.write(json.dumps(error_response, ensure_ascii=False).encode('utf-8'))

# Vercel iÃ§in handler
handler = QueryHandler
